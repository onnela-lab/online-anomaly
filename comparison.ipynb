{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.stats as ss\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def locate_index(value,bin_min,step_size,precision):\n",
    "  loc0 = (value-bin_min)/step_size\n",
    "  if loc0 < 0:\n",
    "    loc = 0\n",
    "  elif loc0 >= precision:\n",
    "    loc = precision-1\n",
    "  else:\n",
    "    loc = int(loc0)\n",
    "  return loc\n",
    "\n",
    "def shift_hist(old_hist,shift):\n",
    "  if shift<0:\n",
    "    left_end = sum(old_hist[:(abs(shift)+1)])\n",
    "    rest = old_hist[(abs(shift)+1):]\n",
    "    fill = np.zeros(len(old_hist)-1-len(rest))\n",
    "    new_hist = np.concatenate(([left_end],rest,fill))\n",
    "  elif shift>0:\n",
    "    right_end = sum(old_hist[-(abs(shift)+1):])\n",
    "    rest = old_hist[:-(abs(shift)+1)]\n",
    "    fill = np.zeros(len(old_hist)-1-len(rest))\n",
    "    new_hist = np.concatenate((fill,rest,[right_end]))\n",
    "  else:\n",
    "    new_hist = old_hist\n",
    "  return new_hist\n",
    "\n",
    "def hist2tilde(hist_j,loc):\n",
    "  cumsum = np.cumsum(np.sum(hist_j,axis=0))\n",
    "  n = cumsum[-1]\n",
    "  percentile = (cumsum[loc]+1)/(n+2)\n",
    "  eps_tilde_j = ss.norm.ppf(percentile)\n",
    "  return eps_tilde_j\n",
    "\n",
    "def eps2tilde(eps):\n",
    "  temp = eps.argsort()\n",
    "  ranks = np.empty_like(temp)\n",
    "  ranks[temp] = np.arange(len(eps))\n",
    "  eps_tilde = ss.norm.ppf((ranks+1)/(len(eps)+1))\n",
    "  return eps_tilde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_hist(data,period,r,precision):\n",
    "  hist_dict = {}\n",
    "  (nrow,ncol) = data.shape\n",
    "  test_stats = np.zeros(nrow)\n",
    "  eps_tilde_mat = np.zeros((nrow,ncol))\n",
    "  bin_min_vec = np.zeros(ncol)\n",
    "  step_size_vec = np.zeros(ncol)\n",
    "  day_sum_mat = np.zeros((period,ncol))\n",
    "  temporal_index = np.arange(nrow)\n",
    "  periodic_index = temporal_index%period\n",
    "  count = np.array([sum(periodic_index==k) for k in range(period)])\n",
    "  for j in range(ncol):\n",
    "    feature = data[:,j]\n",
    "    y_minus_mu = np.zeros(nrow) \n",
    "    eps_hist = np.zeros((period,precision))\n",
    "    for i in range(nrow):\n",
    "      if i<2*period:\n",
    "        mu = np.mean(feature)\n",
    "      else:\n",
    "        w = ss.t.pdf(np.arange(i-1,0,step=-1),2,0,nrow/10)\n",
    "        mu = sum(feature[np.arange(i-1)]*w)/sum(w)\n",
    "      y_minus_mu[i] = feature[i]-mu\n",
    "    day_sum = np.array([sum(y_minus_mu[periodic_index==k]) for k in range(period)])\n",
    "    s = day_sum/count\n",
    "    eps = np.array([y_minus_mu[k]-s[k%period] for k in range(nrow)])\n",
    "    eps_tilde_mat[:,j] = eps2tilde(eps)\n",
    "    diff = max(eps)-min(eps)\n",
    "    bin_min = min(eps)-r*diff\n",
    "    bin_min_vec[j] = bin_min\n",
    "    bin_max = max(eps)+r*diff\n",
    "    step_size = (bin_max-bin_min)/precision\n",
    "    step_size_vec[j] = step_size\n",
    "    for i in range(nrow):\n",
    "      row_loc = i%period\n",
    "      col_loc = locate_index(eps[i],bin_min,step_size,precision)\n",
    "      eps_hist[row_loc, col_loc]=eps_hist[row_loc, col_loc]+1\n",
    "    hist_dict[str(j)] = eps_hist\n",
    "    day_sum_mat[:,j] = day_sum\n",
    "  var = np.cov(eps_tilde_mat,rowvar=False)\n",
    "  for i in range(nrow):\n",
    "    test_stats[i]=eps_tilde_mat[i,:].dot(np.linalg.pinv(var)).dot(eps_tilde_mat[i,:])\n",
    "  memory = data\n",
    "  N = data.shape[0]\n",
    "  return hist_dict,day_sum_mat,count,bin_min_vec,step_size_vec,var,memory,test_stats,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def online_update(new_input,hist_dict,day_sum_mat,count,var,memory,max_storage,N):\n",
    "  (period, ncol) = day_sum_mat.shape\n",
    "  n = sum(count)\n",
    "  eps_vec = np.zeros(ncol)\n",
    "  count[n%period] = count[n%period] + 1\n",
    "  for j in range(ncol):\n",
    "    w = ss.t.pdf(np.arange(memory.shape[0],0,step=-1),2,0,memory.shape[0]/10)\n",
    "    mu = sum(memory[:,j]*w)/sum(w)\n",
    "    y_minus_mu = new_input[j]-mu\n",
    "    old_avg = day_sum_mat[n%period,j]/(count[n%period]-1)\n",
    "    day_sum_mat[n%period,j] = day_sum_mat[n%period,j] +  y_minus_mu\n",
    "    new_avg = day_sum_mat[n%period,j]/count[n%period] \n",
    "    new_eps = y_minus_mu - new_avg\n",
    "    loc = locate_index(new_eps,bin_min_vec[j],step_size_vec[j],precision)\n",
    "    eps_vec[j] = hist2tilde(hist_dict[str(j)],loc)\n",
    "    shift = int(np.round((old_avg-new_avg)/step_size_vec[j],0))\n",
    "    old_hist = hist_dict[str(j)][n%period,:]\n",
    "    new_hist = shift_hist(old_hist,shift)\n",
    "    new_hist[loc] = new_hist[loc] + 1\n",
    "    hist_dict[str(j)][n%period,:] = new_hist\n",
    "  cov = n/(n+1)*var+1/(n+1)*np.outer(eps_vec,eps_vec)\n",
    "  std = np.sqrt(np.diag(cov))\n",
    "  var = cov/np.outer(std,std)\n",
    "  var[cov==0] = 0\n",
    "  stat = eps_vec.dot(np.linalg.pinv(var)).dot(eps_vec)\n",
    "  if n < max_storage:\n",
    "    memory = np.vstack((memory,np.reshape(new_input,(1,ncol))))\n",
    "  else:\n",
    "    memory = memory[1:,:]\n",
    "    memory =  np.vstack((memory,np.reshape(new_input,(1,ncol))))\n",
    "  N = N+1\n",
    "  return stat,hist_dict,day_sum_mat,count,var,memory,N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_perf(pred, truth):\n",
    "  prec = sum((pred==1)*(truth==1))/sum(pred==1)\n",
    "  recall = sum((pred==1)*(truth==1))/sum(truth==1)\n",
    "  F1 = 2*prec*recall/(prec+recall)\n",
    "  return [prec,recall,F1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_var(var):\n",
    "  abs_sum = 0 \n",
    "  raw_sum = 0\n",
    "  count = var.shape[0]*(var.shape[0]-1)/2\n",
    "  for i in np.arange(0,var.shape[0]-1):\n",
    "    for j in np.arange(i+1,var.shape[0]):\n",
    "      abs_sum = abs_sum + abs(var[i,j])\n",
    "      raw_sum = raw_sum + var[i,j]\n",
    "  return abs_sum/count, raw_sum/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find relationship, independent X\n",
    "sim_tab = []\n",
    "for D in [2,5,10,20,30,40,50,60,70]:\n",
    "  for rep in range(5):\n",
    "    K = 1000\n",
    "    data = np.zeros((K,D))\n",
    "    for i in range(D):\n",
    "      scale = np.random.uniform(1e-6,3,size=1)[0]\n",
    "      loc = np.random.uniform(0,7,size=1)[0]\n",
    "      data[:,i] = np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K)\n",
    "    initial_data = data[:100,:]\n",
    "    train_data = data[100:,]\n",
    "    stat_vec = []\n",
    "    hist_dict,day_sum_mat,count,bin_min_vec,step_size_vec,var,memory = initialize_hist(initial_data,period,r,precision)\n",
    "    for i in range(train_data.shape[0]):\n",
    "      new_input = train_data[i,:]\n",
    "      stat,hist_dict,day_sum_mat,count,var,memory = online_update(new_input,hist_dict,day_sum_mat,count,var,memory,max_storage)\n",
    "      stat_vec.append(stat)\n",
    "    p95 = np.percentile(np.array(stat_vec),95)\n",
    "    abs_var, raw_var = mag_var(var)\n",
    "    sim_tab.append([D,rep,p95,ss.chi2.ppf(0.95,D),abs_var,raw_var])\n",
    "sim_tab = np.array(sim_tab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlated\n",
    "sim_tab = []\n",
    "for D in [2,5,10,20,30,40,50,60,70]:\n",
    "  for rep in range(20):\n",
    "    K = 1000\n",
    "    data = np.zeros((K,D))\n",
    "    for i in range(D):\n",
    "      scale = np.random.uniform(1e-6,3,size=1)[0]\n",
    "      loc = np.random.uniform(0,7,size=1)[0]\n",
    "      if i>0:\n",
    "        w = np.random.uniform(-0.7,0.7,size=1)[0]\n",
    "        data[:,i] = (1-w)*(np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K))+w*data[:,i-1]\n",
    "      else:\n",
    "        data[:,i] = np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K)\n",
    "    initial_data = data[:100,:]\n",
    "    train_data = data[100:,]\n",
    "    stat_vec = []\n",
    "    hist_dict,day_sum_mat,count,bin_min_vec,step_size_vec,var,memory = initialize_hist(initial_data,period,r,precision)\n",
    "    for i in range(train_data.shape[0]):\n",
    "      new_input = train_data[i,:]\n",
    "      stat,hist_dict,day_sum_mat,count,var,memory = online_update(new_input,hist_dict,day_sum_mat,count,var,memory,max_storage)\n",
    "      stat_vec.append(stat)\n",
    "    p95 = np.percentile(np.array(stat_vec),95)\n",
    "    abs_var, raw_var = mag_var(var)\n",
    "    sim_tab.append([D,rep,p95,ss.chi2.ppf(0.95,D),abs_var,raw_var])\n",
    "sim_tab = np.array(sim_tab)\n",
    "pd.DataFrame(sim_tab).to_csv(\"C:/Users/glius/Downloads/sim_cor.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "## three predictors abs_var, D and ss.chi2.ppf(0.95,D)\n",
    "def find_threshold(var,D):\n",
    "  abs_sum = 0 \n",
    "  count = D*(D-1)/2\n",
    "  for i in np.arange(0,D-1):\n",
    "    for j in np.arange(i+1,D):\n",
    "      abs_sum = abs_sum + abs(var[i,j])\n",
    "  mean_cor = abs_sum/count\n",
    "  chi2 = ss.chi2.ppf(0.95,D)\n",
    "  threshold = 0.1877 + 0.0334*D + 0.9231*chi2 + 0.6314*mean_cor - 0.1763*chi2*mean_cor \n",
    "  return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6000\n",
    "D = 20\n",
    "p = 0.03\n",
    "data = np.zeros((K,D))\n",
    "for i in range(D):\n",
    "  scale = np.random.uniform(1e-6,3,size=1)[0]\n",
    "  loc = np.random.uniform(0,7,size=1)[0]\n",
    "  if i>0:\n",
    "    w = np.random.uniform(0.2,0.8,size=1)[0]\n",
    "    data[:,i] = w*(np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K))+(1-w)*data[:,i-1]\n",
    "  else:\n",
    "    data[:,i] = np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K)\n",
    "anomaly_index = np.sort(np.random.choice(np.arange(K), size=int(K*p), replace= False))\n",
    "for i in anomaly_index:\n",
    "  aberrant_num = np.random.choice(np.arange(int(D*0.3),int(D*0.7)))\n",
    "  aberrant_col = np.random.choice(np.arange(D),aberrant_num,replace = False)\n",
    "  data[i,aberrant_col] = data[i,aberrant_col]*np.random.uniform(0.33,3,size=aberrant_num)\n",
    "initial_data = data[:100,:]\n",
    "train_data = data[np.arange(100,int(K/2)),:]\n",
    "test_data = data[int(K/2):,:]\n",
    "labels = np.zeros(K)\n",
    "labels[anomaly_index[anomaly_index>=int(K/2)]] = 1\n",
    "train_labels = labels[:int(K/2)]\n",
    "test_labels = labels[int(K/2):]\n",
    "mad_gan_train = np.hstack((np.vstack((initial_data,train_data)),train_labels.reshape(-1,1)))\n",
    "mad_gan_test = np.hstack((test_data,test_labels.reshape(-1,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 21)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save('C:/Users/glius/Downloads/MAD-GANs-master/data/sim_train.npy',mad_gan_train)\n",
    "np.save('C:/Users/glius/Downloads/MAD-GANs-master/data/sim_test.npy',mad_gan_test)\n",
    "mad_gan_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000, 20, 0.005, 0.15384615384615385, 0.5, 0.23529411764705882, 0.15384615384615385, 0.5, 0.23529411764705882, 20.569292]\n",
      "[2000, 20, 0.015, 1.0, 0.5833333333333334, 0.7368421052631579, 1.0, 0.5833333333333334, 0.7368421052631579, 20.239179]\n",
      "[2000, 20, 0.045, 1.0, 0.2631578947368421, 0.4166666666666667, 1.0, 0.2631578947368421, 0.4166666666666667, 20.494994]\n",
      "[2000, 40, 0.005, 0.3684210526315789, 1.0, 0.5384615384615384, 0.3684210526315789, 1.0, 0.5384615384615384, 40.541098]\n",
      "[2000, 40, 0.015, 0.8181818181818182, 0.5625, 0.6666666666666666, 0.8571428571428571, 0.75, 0.7999999999999999, 41.579796]\n",
      "[2000, 40, 0.045, 1.0, 0.9512195121951219, 0.975, 1.0, 0.9512195121951219, 0.975, 40.806535]\n",
      "[2000, 80, 0.005, 0.8571428571428571, 1.0, 0.923076923076923, 0.6, 1.0, 0.7499999999999999, 100.426506]\n",
      "[2000, 80, 0.015, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 99.19761]\n",
      "[2000, 80, 0.045, 1.0, 0.9130434782608695, 0.9545454545454545, 1.0, 0.9130434782608695, 0.9545454545454545, 99.970841]\n",
      "[4000, 20, 0.005, 0.5625, 0.9, 0.6923076923076923, 0.6428571428571429, 0.9, 0.75, 44.466174]\n",
      "[4000, 20, 0.015, 1.0, 0.4230769230769231, 0.5945945945945945, 1.0, 0.4230769230769231, 0.5945945945945945, 44.459419]\n",
      "[4000, 20, 0.045, 0.9302325581395349, 0.47058823529411764, 0.625, 0.9318181818181818, 0.4823529411764706, 0.6356589147286822, 44.103146]\n",
      "[4000, 40, 0.005, 0.3793103448275862, 1.0, 0.5499999999999999, 0.3235294117647059, 1.0, 0.48888888888888893, 88.704458]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-478-6bcac7b95dab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     65\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mnew_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mstat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday_sum_mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0monline_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhist_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mday_sum_mat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mthreshold95\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m           \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mthreshold95\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-477-5912b3568ad7>\u001b[0m in \u001b[0;36monline_update\u001b[1;34m(new_input, hist_dict, day_sum_mat, count, var, memory, max_storage, N)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mcount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mperiod\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mncol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mmu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0my_minus_mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_input\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36mpdf\u001b[1;34m(self, x, *args, **kwds)\u001b[0m\n\u001b[0;32m   1659\u001b[0m             \u001b[0mgoodargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margsreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m             \u001b[0mscale\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoodargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoodargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1661\u001b[1;33m             \u001b[0mplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcond\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgoodargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1663\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m_pdf\u001b[1;34m(self, x, df)\u001b[0m\n\u001b[0;32m   4679\u001b[0m         \u001b[1;31m# t.pdf(x, df) = ---------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4680\u001b[0m         \u001b[1;31m#                sqrt(pi*df) * gamma(df/2) * (1+x**2/df)**((df+1)/2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4681\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4682\u001b[0m         \u001b[0mPx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgammaln\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgammaln\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4683\u001b[0m         \u001b[0mPx\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## simulation\n",
    "period = 7\n",
    "r = 0.15\n",
    "precision = 1000\n",
    "max_storage = 1000\n",
    "g = 100\n",
    "h = 4\n",
    "\n",
    "results = []\n",
    "for K in [2000,4000,8000]:\n",
    "  for D in [20, 40, 80]:\n",
    "    for p in [0.005, 0.015, 0.045]:\n",
    "      data = np.zeros((K,D))\n",
    "      for i in range(D):\n",
    "        scale = np.random.uniform(1e-6,3,size=1)[0]\n",
    "        loc = np.random.uniform(0,7,size=1)[0]\n",
    "        if i>0:\n",
    "          w = np.random.uniform(0.2,0.8,size=1)[0]\n",
    "          data[:,i] = w*(np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K))+(1-w)*data[:,i-1]\n",
    "        else:\n",
    "          data[:,i] = np.array([scale*np.sin(2*math.pi/7*(x+loc)) for x in range(K)]) + np.random.normal(0,scale,K)\n",
    "      anomaly_index = np.sort(np.random.choice(np.arange(K), size=int(K*p), replace= False))\n",
    "      for i in anomaly_index:\n",
    "        aberrant_num = np.random.choice(np.arange(int(D*0.3),int(D*0.7)))\n",
    "        aberrant_col = np.random.choice(np.arange(D),aberrant_num,replace = False)\n",
    "        data[i,aberrant_col] = data[i,aberrant_col]*np.random.uniform(0.33,3,size=aberrant_num)\n",
    "      initial_data = data[:100,:]\n",
    "      train_data = data[np.arange(100,int(K/2)),:]\n",
    "      test_data = data[int(K/2):,:]\n",
    "      labels = np.zeros(K)\n",
    "      labels[anomaly_index[anomaly_index>=int(K/2)]] = 1\n",
    "      train_labels = labels[:int(K/2)]\n",
    "      test_labels = labels[int(K/2):]\n",
    "      \n",
    "      anomaly_hist = np.zeros(g)\n",
    "      t0 = datetime.now()\n",
    "      hist_dict,day_sum_mat,count,bin_min_vec,step_size_vec,var,memory,test_stats,N = initialize_hist(initial_data,period,r,precision)\n",
    "      threshold95 = find_threshold(var,D)\n",
    "      step = threshold95/(D*2)\n",
    "      found = 0\n",
    "      for i in range(N):\n",
    "        if test_stats[i]>threshold95:\n",
    "          index = min(int((test_stats[i]-threshold95)/step),g-1)\n",
    "          anomaly_hist[index] = anomaly_hist[index] + 1\n",
    "      \n",
    "      reverse_cumsum =  np.cumsum(np.flip(anomaly_hist,axis=0))\n",
    "      if sum(anomaly_hist)>N*0.05:\n",
    "        found = 1\n",
    "        reverse_count = int(np.ceil(sum(anomaly_hist)-N*0.05))\n",
    "        if reverse_cumsum[0]>reverse_count+1:\n",
    "          index = 0\n",
    "        else:\n",
    "          index = np.where(reverse_cumsum>=reverse_count+1)[0][0]\n",
    "        threshold_anomaly = threshold95 + (g-index)*step\n",
    "      else:\n",
    "        observed = 1\n",
    "        for i in np.arange(1,g):\n",
    "          if reverse_cumsum[i]!=reverse_cumsum[i-1]:\n",
    "            observed = observed + 1\n",
    "            if observed == h or i==g-1:\n",
    "              threshold_anomaly = threshold95 + (g-i)*step\n",
    "              break\n",
    " \n",
    "\n",
    "      for i in range(train_data.shape[0]):\n",
    "        new_input = train_data[i,:]\n",
    "        stat,hist_dict,day_sum_mat,count,var,memory,N = online_update(new_input,hist_dict,day_sum_mat,count,var,memory,max_storage,N)\n",
    "        if stat>threshold95:\n",
    "          index = min(int((stat-threshold95)/step),g-1)\n",
    "          anomaly_hist[index] = anomaly_hist[index] + 1\n",
    "        \n",
    "        reverse_cumsum =  np.cumsum(np.flip(anomaly_hist,axis=0))\n",
    "        if sum(anomaly_hist)>N*0.05:\n",
    "          found = 1\n",
    "          reverse_count = int(np.ceil(sum(anomaly_hist)-N*0.05))\n",
    "          if reverse_cumsum[0]>reverse_count+1:\n",
    "            index = 0\n",
    "          else:\n",
    "            index = np.where(reverse_cumsum>=reverse_count+1)[0][0]\n",
    "          threshold_anomaly = threshold95 + (g-index)*step\n",
    "        elif found==0:\n",
    "          observed = 1\n",
    "          for i in np.arange(1,g):\n",
    "            if reverse_cumsum[i]!=reverse_cumsum[i-1]:\n",
    "              observed = observed + 1\n",
    "              if observed == h or i == g-1:\n",
    "                threshold_anomaly = threshold95 + (g-i)*step\n",
    "                break\n",
    "        else:\n",
    "          threshold_anomaly = threshold_anomaly\n",
    "          \n",
    "      \n",
    "      pred_fly = []\n",
    "      stat_retro = []\n",
    "      for i in range(test_data.shape[0]):\n",
    "        new_input = test_data[i,:]\n",
    "        stat,hist_dict,day_sum_mat,count,var,memory,N = online_update(new_input,hist_dict,day_sum_mat,count,var,memory,max_storage,N)\n",
    "        if stat>threshold95:\n",
    "          index = min(int((stat-threshold95)/step),g-1)\n",
    "          anomaly_hist[index] = anomaly_hist[index] + 1\n",
    "       \n",
    "        reverse_cumsum =  np.cumsum(np.flip(anomaly_hist,axis=0))\n",
    "        if sum(anomaly_hist)>N*0.05:\n",
    "          found = 1\n",
    "          reverse_count = int(np.ceil(sum(anomaly_hist)-N*0.05))\n",
    "          if reverse_cumsum[0]>reverse_count+1:\n",
    "            index = 0\n",
    "          else:\n",
    "            index = np.where(reverse_cumsum>=reverse_count+1)[0][0]\n",
    "          threshold_anomaly = threshold95 + (g-index)*step\n",
    "        elif found==0:\n",
    "          observed = 1\n",
    "          for i in np.arange(1,g):\n",
    "            if reverse_cumsum[i]!=reverse_cumsum[i-1]:\n",
    "              observed = observed + 1\n",
    "              if observed == h or i==g-1:\n",
    "                threshold_anomaly = threshold95 + (g-i)*step\n",
    "                break\n",
    "        else:\n",
    "          threshold_anomaly = threshold_anomaly\n",
    "        pred_fly.append(stat>threshold_anomaly)\n",
    "        stat_retro.append(stat)\n",
    "        \n",
    "      t1 = datetime.now()\n",
    "      t_need = (t1-t0).total_seconds()\n",
    "      pred_fly = np.array(pred_fly)*1\n",
    "      pred_retro = (np.array(stat_retro)>threshold_anomaly)*1\n",
    "      eval_fly = eval_perf(pred_fly, test_labels)\n",
    "      eval_retro = eval_perf(pred_retro, test_labels)\n",
    "      print([K,D,p,eval_fly[0],eval_fly[1],eval_fly[2],eval_retro[0],eval_retro[1],eval_retro[2],t_need])\n",
    "      results.append([K,D,p,eval_fly[0],eval_fly[1],eval_fly[2],eval_retro[0],eval_retro[1],eval_retro[2],t_need])\n",
    "      temp = np.array(results)\n",
    "      np.save(\"C:/Users/glius/Downloads/sim_result.npy\",temp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
